{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import re \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "toggleable": false,
    "ulab": {
     "buttons": {
      "ulab-button-toggle-1d974c28": {
       "style": "primary"
      }
     }
    }
   },
   "source": [
    "### Scope \n",
    "In this project, we will collect I94(immigration data) and create a dimention table from it. Next, we will gather a temperature data city wise and load into a dimention table. \n",
    "\n",
    "Next we will be joining these two datasets and analyze on how the temperature of a city can play a role in people immigrating to it. \n",
    "\n",
    "We shall be using SPARK to analyze the data.\n",
    "\n",
    "#### About the Data and where to find it. \n",
    "I94 data came be taken from [here](https://travel.trade.gov/research/reports/i94/historical/2016.html).We have got a sample of the data in the course for our analysis. \n",
    "It is provided to us in SAS7BDAT formart. \n",
    "\n",
    "**Data Attributes(I94)**:\n",
    "\n",
    "* i94yr = Year in 4 digits. \n",
    "* i94mon = Month of the immingration(in mumeric). \n",
    "* i94cit = Orgin city's code.(3 Digit) \n",
    "* i94port = Destination USA city code( 3 digit) \n",
    "* arrddate = arrival date in US. \n",
    "* i94mode = Travel code( 1 digit). \n",
    "* depdate = Deperature date from US. \n",
    "* i94visa = Immigration VISA. \n",
    "\n",
    "Temperature data can be collected from [Kragge](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data) Data format is .csv\n",
    "\n",
    "**Data Attributes(Temperature)**: \n",
    "\n",
    "* AverageTemperature = Average Temperature\n",
    "* City = City Name\n",
    "* Country = Country Name\n",
    "* Latitude= Latitude\n",
    "* Longitude = Longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(file, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ã…rhus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Ã…rhus   \n",
       "1  1743-12-01                 NaN                            NaN  Ã…rhus   \n",
       "2  1744-01-01                 NaN                            NaN  Ã…rhus   \n",
       "3  1744-02-01                 NaN                            NaN  Ã…rhus   \n",
       "4  1744-03-01                 NaN                            NaN  Ã…rhus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read in the temperature data into Pandas for exploration\n",
    "file_temperature = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "df_temperature = pd.read_csv(file_temperature, sep=',')\n",
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#creating a sparksession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary of valid i94port codes\n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "valid_i94_port = {}\n",
    "with open('port_valid.txt') as file:\n",
    "     for line in file:\n",
    "         match = re_obj.search(line)\n",
    "         valid_i94_port[match[1]]=[match[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean I94 immigration data\n",
    "def clean_data(file):\n",
    "    '''    \n",
    "    Input: Path to I94 immigration data file\n",
    "    Output: Returns a spark dataframe of I94 immigration data with valid i94port\n",
    "    '''    \n",
    "    # Read I94 data into Spark\n",
    "    df_immigration = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "\n",
    "    # Filter out entries where i94port is invalid\n",
    "    df_immigration = df_immigration.filter(df_immigration.i94port.isin(list(valid_i94_port.keys())))\n",
    "\n",
    "    return df_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(cicid=7.0, i94yr=2016.0, i94mon=4.0, i94cit=254.0, i94res=276.0, i94port='ATL', arrdate=20551.0, i94mode=1.0, i94addr='AL', depdate=None, i94bir=25.0, i94visa=3.0, count=1.0, dtadfile='20130811', visapost='SEO', occup=None, entdepa='G', entdepd=None, entdepu='Y', matflag=None, biryear=1991.0, dtaddto='D/S', gender='M', insnum=None, airline=None, admnum=3736796330.0, fltno='00296', visatype='F1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function smoke test\n",
    "immigration_test_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' \n",
    "df_test = clean_data(immigration_test_file)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean temperature data\n",
    "df_temperature = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dt='1743-11-01', AverageTemperature='6.068', AverageTemperatureUncertainty='1.7369999999999999', City='Ã…rhus', Country='Denmark', Latitude='57.05N', Longitude='10.33E')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filter out data points with NaN average temperature\n",
    "df_temperature = df_temperature.filter(df_temperature.AverageTemperature != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicate locations\n",
    "df_temperature = df_temperature.dropDuplicates(['City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@udf()\n",
    "def get_i94port(city):\n",
    "    '''\n",
    "    Input: City name\n",
    "    \n",
    "    Output: Corresponding i94port\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for key in valid_i94_port:\n",
    "        if city.lower() in valid_i94_port[key][0].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Add iport94 code based on city name\n",
    "df_temperature = df_temperature.withColumn(\"i94port\", get_i94port(df_temperature.City))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove data points with no iport94 code\n",
    "df_temperature = df_temperature.filter(df_temperature.i94port != 'null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dt='1852-07-01', AverageTemperature='15.488', AverageTemperatureUncertainty='1.395', City='Perth', Country='Australia', Latitude='31.35S', Longitude='114.97E', i94port='PER')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show results\n",
    "df_temperature.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "**Fact Table** - This table contains the information for the immigration data and temperature which are clubbed together on the column *i94* port. \n",
    "\n",
    "*columns*: \n",
    "* i94yr   =  4 Digit year\n",
    "* i94mon  =  Numeric month\n",
    "* i94cit  =  3 Digit code of Origin City\n",
    "* i94port =  3 character code of Destination City\n",
    "* arrdate =  Arrival date into US \n",
    "* i94mode =  1 digit of travel code\n",
    "* depdate =  Departure date\n",
    "* i94visa =  Reason for immigration\n",
    "* AverageTemperature = Average temperature of destination city\n",
    "\n",
    "*Dimention Tables*: \n",
    "\n",
    "1. Immigration Table: \n",
    "* i94yr   =  4 Digit year\n",
    "* i94mon  =  Numeric month\n",
    "* i94cit  =  3 Digit code of Origin City\n",
    "* i94port =  3 character code of Destination City\n",
    "* arrdate =  Arrival date into US\n",
    "* i94mode =  1 digit of travel code\n",
    "* depdate =  Departure date\n",
    "* i94visa =  Reason for immigration\n",
    "\n",
    "2. Temperature Table: \n",
    "* i94port = 3 Digit char code of Destination city(acheived during clean up) \n",
    "* City    = City Name\n",
    "* Country = Country Name\n",
    "* AverageTemperature = Average Temperature in the City\n",
    "* Latitude = Latitude\n",
    "* Longitude = Longitude\n",
    "\n",
    "These tables will be stored in Parquet and will be partioned based on the City(i94port) in US.\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "1. Creak a SPARK dataframe for the immigration data and clean it as mentioned above. \n",
    "2. Create a SPARK dataframe for the temperature data and clean it. \n",
    "3. From the immigration data, select the columns which are necesarry and write them to parquet file which is partioned on i94port. This will be one the dimention table. \n",
    "4. From the temperature data, select the necessary columns and write them to parquet file which is partioned on i94port. This will be the next dimention table.  \n",
    "5. Now create a fact table by joining the above immigration and temperature data on i94 port and wite them to parquet file file which is partioned on i94port. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Path to I94 data \n",
    "#immigration_data_path = '/data/18-83510-I94-Data-2016/*.sas7bdat'\n",
    "immigration_data_path = '/data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "\n",
    "#Loading i94 data into a spark dataframe and cleaning it.\n",
    "data_frame_immigration = clean_i94_data(immigration_data_path)\n",
    "\n",
    "# Extracting columns \n",
    "immigration_data = data_frame_immigration.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"])\n",
    "\n",
    "# Writing immigration dataframe to parquet files partitioned on i94port\n",
    "immigration_data.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extracting columns for temperature table\n",
    "temperature_data = df_temperature.select([\"AverageTemperature\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"i94port\"])\n",
    "\n",
    "# Writing temperature dataframe table to parquet files partitioned on i94port\n",
    "temperature_data.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/temperature.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating Temporary views of the immigration and temperature data\n",
    "data_frame_immigration.createOrReplaceTempView(\"v_immigration\")\n",
    "temperature_data.createOrReplaceTempView(\"v_temperature\")\n",
    "\n",
    "# Creating the fact table by joining the immigration and temperature view on i94port\n",
    "fact_table = spark.sql('''\n",
    "SELECT v_immigration.i94yr as year,\n",
    "       v_immigration.i94mon as month,\n",
    "       v_immigration.i94cit as mity,\n",
    "       v_immigration.i94port as i94port,\n",
    "       v_immigration.arrdate as arrival_date,\n",
    "       v_immigration.depdate as departure_date,\n",
    "       v_immigration.i94visa as reason,\n",
    "       v_temperature.AverageTemperature as temperature,\n",
    "       v_temperature.Latitude as latitude,\n",
    "       v_temperature.Longitude as longitude\n",
    "FROM v_immigration\n",
    "JOIN v_temperature ON (v_immigration.i94port = v_temperature.i94port)\n",
    "''')\n",
    "\n",
    "# Writing the fact table to parquet file partitioned on i94port\n",
    "fact_table.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/fact.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Data Qaulity is to ensure the records are present in the table as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def quality_check(df, description):\n",
    "    '''\n",
    "    Input: Spark dataframe, description dataframe\n",
    "    \n",
    "    Output: Prints the output of data quality check\n",
    "    '''\n",
    "    result = df.count()\n",
    "    \n",
    "    if result == 0:\n",
    "        print(\"There are zero records in {}. Data has NOT been processed sucessfully\".format(description))\n",
    "    else:\n",
    "        print(\"{} has {} records\".format(description.capitalize(), result))\n",
    "    return 0\n",
    "\n",
    "# Perform data quality check\n",
    "quality_check(data_frame_immigration, \"immigration table\")\n",
    "quality_check(temperature_data, \"temperature table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "**Fact Table** - This table contains the information for the immigration data and temperature which are clubbed together on the column *i94* port. \n",
    "\n",
    "*columns*: \n",
    "* i94yr   =  4 Digit year\n",
    "* i94mon  =  Numeric month\n",
    "* i94cit  =  3 Digit code of Origin City\n",
    "* i94port =  3 character code of Destination City\n",
    "* arrdate =  Arrival date into US \n",
    "* i94mode =  1 digit of travel code\n",
    "* depdate =  Departure date\n",
    "* i94visa =  Reason for immigration\n",
    "* AverageTemperature = Average temperature of destination city\n",
    "\n",
    "*Dimention Tables*: \n",
    "\n",
    "1. Immigration Table: \n",
    "* i94yr   =  4 Digit year\n",
    "* i94mon  =  Numeric month\n",
    "* i94cit  =  3 Digit code of Origin City\n",
    "* i94port =  3 character code of Destination City\n",
    "* arrdate =  Arrival date into US\n",
    "* i94mode =  1 digit of travel code\n",
    "* depdate =  Departure date\n",
    "* i94visa =  Reason for immigration\n",
    "\n",
    "2. Temperature Table: \n",
    "* i94port = 3 Digit char code of Destination city(acheived during clean up) \n",
    "* City    = City Name\n",
    "* Country = Country Name\n",
    "* AverageTemperature = Average Temperature in the City\n",
    "* Latitude = Latitude\n",
    "* Longitude = Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Project Write Up\n",
    "\n",
    "**Technology**\n",
    "\n",
    "* SPARK has been choosen because of its power to process large data scale. Secound reason for the choosing spark is because of its power to deal with mutilple data fromatas(example here SAS). \n",
    "* Leveraged SparkSQL to process large amount of data by converting the data into data frames and processing it. Like cleaning and slection. \n",
    "\n",
    "**Frequency of Update**\n",
    "\n",
    "* Data should be updated on a monthy basis as source of the data is a montly load. \n",
    "\n",
    "#### Edge Case Conditions\n",
    "\n",
    "1. If the Data is increased by 100x. \n",
    "    Using a Cloud Based approach will help us to scale up powerful machines on demand and scale down.\n",
    "    \n",
    "    \n",
    "2. The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "    We can use orchestrator(Ozzie or Airflow) to run the pipeline on demand basis. The result of the pipeline will be read by the dashboard and be populated. We will be using orchestator's alert functionality to alert us on errors. \n",
    "    \n",
    "    \n",
    "3. The database needed to be accessed by 100+ people.\n",
    "    * If we have a Hadoop cluster, we can push the data to HDFS and let the users read this data from Hive or Presto. \n",
    "    * If we are using a cloud platform(AWS or GCP), we will be writing the data to Redshift or Bigquey and use their's fucntionality to sever our users. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
